import cv2
import numpy as np
from motion_marmot.simple_scene_classifier import SimpleSceneClassifier


class AdvancedMotionFilter():
    """
    Advanced Motion Filter is using the parameters extracted from MOG2 mask
    and filter out all possible FN scenes according to these parameters
    """

    def __init__(
        self,
        ssc_model: str,
        frame_width: int,
        frame_height: int,
        amf_history_variance=False,
        amf_variance_threshold=100,
        amf_variance_sample_amount=5,
        amf_frame_reduction=False,
        amf_drop_large_bg_motion=False,
        amf_dynamic_bbx=False
    ):
        self.mog2 = cv2.createBackgroundSubtractorMOG2()

        self.amf_history_variance = amf_history_variance
        self.amf_variance_threshold = amf_variance_threshold
        self.amf_variance_sample_amount = amf_variance_sample_amount
        self.amf_frame_reduction = amf_frame_reduction
        self.amf_drop_large_bg_motion = amf_drop_large_bg_motion
        self.amf_dynamic_bbx = amf_dynamic_bbx

        self.frame_width = frame_width
        self.frame_height = frame_height

        self.ssc = SimpleSceneClassifier("For Advanced Motion Filter", ssc_model)
        self.prev_frame_storage = []
        self.prev_drop_flag = False

    def __str__(self):
        return f"AdvancedMotionFilter(ssc={self.ssc})"

    def apply(self, frame):
        mask = self.mog2.apply(frame)
        return mask

    def calculate_contours(self, mask):
        return cv2.findContours(
            mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )[0]

    def detect_motion(self, mask, min_area):

        motion_bbxes = []

        # calculate related parameters according to the motion mask
        mask_metadata = MotionMaskMetadata(
            cv2.findContours(
                mask.copy(),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE
            )[0]
        )
        variance = self.calculate_variance(mask_metadata.std)

        # use contours variance to drop sudden motion
        if self.amf_history_variance:
            history_variance_bool = variance < self.amf_variance_threshold
            if not history_variance_bool:
                return []

        # Filtered by Simple Scene Classifier
        if self.amf_drop_large_bg_motion or self.amf_dynamic_bbx:
            # use KNN Simple Scene Classifier to classify frame scene
            frame_scene = self.ssc.predict(
                mask_metadata.avg,
                mask_metadata.std,
                self.frame_width,
                self.frame_height
            )
            # drop large background motion
            if self.amf_drop_large_bg_motion and frame_scene == 3:
                return []
            # adjust bounding box threshold (aka min_area) if the motion is small
            if self.amf_dynamic_bbx and frame_scene == 2:
                min_area = mask_metadata.avg + mask_metadata.std

        for i, area in enumerate(mask_metadata.contour_area_list):
            if area < min_area:
                continue
            (x, y, w, h) = cv2.boundingRect(mask_metadata.contours[i])
            motion_bbxes.append((x, y, w, h))

        return motion_bbxes

    def draw_detection_box(self, box, frame):
        cv2.rectangle(frame, (box.x, box.y), (box.x + box.w, box.y + box.h), (255, 0, 0), 2)

    def calculate_variance(self, std):
        self.prev_frame_storage.append(std)
        if len(self.prev_frame_storage) > self.amf_variance_sample_amount:
            self.prev_frame_storage.pop(0)
        variance = np.var(self.prev_frame_storage) if self.prev_frame_storage else 0
        return variance


class BoundingBox():
    """A rectangle bounding box that bounding motion mask detection contour"""

    def __init__(self, x, y, w, h):
        self.x = x
        self.y = y
        self.w = w
        self.h = h


class MotionMaskMetadata():
    """
    The class contains related features of motion masks which is generated by MOG2 in OpenCV
    """

    def __init__(self, contours):
        self.contours = contours
        self.contour_area_list = [cv2.contourArea(contour) for contour in self.contours]
        self.total = sum(self.contour_area_list)
        self.avg = self.total / len(self.contour_area_list) if self.contour_area_list else 0
        self.std = np.std(np.array(self.contour_area_list)) if self.contour_area_list else 0


class FD():
    """
    Frame Difference Motion Filter
    """

    def __init__(self):
        self.avg_frame = None

    def apply(self, frame, delta_thresh=5, isBlur=True):
        """
        Apply the motion filter
        """
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        if isBlur:
            gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)
        if self.avg_frame is None:
            self.avg_frame = gray_frame.copy().astype("float")
        cv2.accumulateWeighted(gray_frame, self.avg_frame, 0.5)
        frame_delta = cv2.absdiff(
            gray_frame, cv2.convertScaleAbs(self.avg_frame)
        )

        fd_mask = cv2.threshold(frame_delta, delta_thresh, 255, cv2.THRESH_BINARY)[1]
        fd_mask = cv2.dilate(fd_mask, None, iterations=2)

        return fd_mask.copy()
